{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings or features from prior steps\n",
    "# Placeholder: Replace with actual paths or download links\n",
    "zillow_df = gpd.read_file('../dataset/raw/2. zillow_cleaned.geojson')\n",
    "w2v_emb = pd.read_csv('../dataset/raw/4. w2v_embedding.csv')\n",
    "w2v_pca = pd.read_csv('../dataset/raw/4. w2v_pca.csv')\n",
    "bert_emb = pd.read_csv('../dataset/raw/4. bert_embedding.csv')\n",
    "bert_pca = pd.read_csv('../dataset/raw/4. bert_pca.csv')\n",
    "stf_emb = pd.read_csv('../dataset/raw/5. stf_embedding.csv')\n",
    "stf_pca = pd.read_csv('../dataset/raw/5. stf_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully: (10111, 385)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Dropbox direct download link\n",
    "url_gpt_emb = 'https://www.dropbox.com/scl/fi/gcrk2mejy3su7nt9gf30i/5.-stf_embedding.csv?rlkey=d5uy0qm80geh81qxhxbtyms66&st=46sngliz&dl=1'\n",
    "\n",
    "# Load directly into DataFrame\n",
    "response = requests.get(url_gpt_emb)\n",
    "if response.status_code == 200:\n",
    "    gpt_emb = pd.read_csv(StringIO(response.text))\n",
    "    print(\"CSV loaded successfully:\", gpt_emb.shape)\n",
    "else:\n",
    "    print(\"Failed to fetch the file:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully: (10111, 33)\n"
     ]
    }
   ],
   "source": [
    "# Dropbox direct download link\n",
    "url_gpt_pca = 'https://www.dropbox.com/scl/fi/6gdiftk79r00a3uecf9zv/5.-stf_pca.csv?rlkey=j8e7e5tt81w2yt6fd3968mdwp&st=5wwf7fib&dl=1'\n",
    "\n",
    "# Load directly into DataFrame\n",
    "response = requests.get(url_gpt_pca)\n",
    "if response.status_code == 200:\n",
    "    gpt_pca = pd.read_csv(StringIO(response.text))\n",
    "    print(\"CSV loaded successfully:\", gpt_pca.shape)\n",
    "else:\n",
    "    print(\"Failed to fetch the file:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = zillow_df.copy()\n",
    "\n",
    "zillow_df['zpid'] = zillow_df['zpid'].astype(str)\n",
    "w2v_emb['zpid'] = w2v_emb['zpid'].astype(str)\n",
    "bert_emb['zpid'] = bert_emb['zpid'].astype(str)\n",
    "stf_emb['zpid'] = stf_emb['zpid'].astype(str)\n",
    "gpt_emb['zpid'] = gpt_emb['zpid'].astype(str)\n",
    "df_all = df_all.merge(w2v_emb, on=\"zpid\", how=\"left\")\n",
    "df_all = df_all.merge(bert_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_bert\"))\n",
    "df_all = df_all.merge(stf_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_stf\"))\n",
    "df_all = df_all.merge(gpt_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_gpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Label: Fast-Selling (TOP 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['duration'] = df_all['duration'].astype(float)\n",
    "df_all['city'] = df_all['city'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fast_label(group):\n",
    "    threshold = group['duration'].quantile(0.25)\n",
    "    return group['duration'] <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdsn\\AppData\\Local\\Temp\\ipykernel_176560\\2106994927.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_all['fast_label'] = df_all.groupby('city', group_keys=False).apply(assign_fast_label).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_all['fast_label'] = df_all.groupby('city', group_keys=False).apply(assign_fast_label).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLaMA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c92a60c904241e98263cb88d5d8bc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "llama_32_1b = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "llama_32_3b = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "generator = pipeline(model=llama_32_3b, device=device, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zero_shot_prompt(row):\n",
    "    return f\"\"\"\n",
    "    <Task> Classify whether the house is fast-selling or not.\n",
    "    <House Info>\n",
    "    - Address: {row['address']}, {row['city']}\n",
    "    - Type: {'Single Family' if row['single'] == 0 else 'Condo/Townhouse'}\n",
    "    - Description: {row['description']}\n",
    "    - Days on Market: {row['duration']}\n",
    "    <Question> Is this a fast-selling house? Answer only 'Yes' or 'No'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_prompt(row, embedding_columns):\n",
    "    embed_values = \", \".join([f\"{col}: {row[col]:.4f}\" for col in embedding_columns if not pd.isna(row[col])])\n",
    "    return f\"\"\"\n",
    "    <Task> Given the house description and its embedding values, classify whether the house is fast-selling.\n",
    "    <Description>: {row['description']}\n",
    "    <Embeddings>: {embed_values}\n",
    "    <Question>: Is this a fast-selling house? Answer 'Yes' or 'No'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_few_shot_prompt(df_context, row):\n",
    "    examples = \"\\n\".join([\n",
    "        f\"Example {i+1} -> Description: {r['description']}\\nFast Selling: {'Yes' if r['fast_label'] else 'No'}\"\n",
    "        for i, (_, r) in enumerate(df_context.iterrows())\n",
    "    ])\n",
    "    return f\"\"\"\n",
    "    <Task> Determine whether the house is fast-selling based on its description.\n",
    "    {examples}\n",
    "    Now classify this house:\n",
    "    Description: {row['description']}\n",
    "    <Question> Fast Selling? Answer 'Yes' or 'No'.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llama_classification(df_subset, prompt_func, prompt_args=None):\n",
    "    predictions = []\n",
    "    for _, row in df_subset.iterrows():\n",
    "        if prompt_args:\n",
    "            prompt = prompt_func(row, **prompt_args)\n",
    "        else:\n",
    "            prompt = prompt_func(row)\n",
    "        result = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=generator.tokenizer.eos_token_id\n",
    "        )[0]['generated_text']\n",
    "        predictions.append(\"Yes\" in result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data sample\n",
    "sample_df = df_all.dropna(subset=['description', 'duration']).sample(n=50, random_state=42)\n",
    "y_true = sample_df['fast_label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Zero-shot ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Zero-shot ---\")\n",
    "y_pred_zero = run_llama_classification(sample_df, build_zero_shot_prompt)\n",
    "evaluate(y_true, y_pred_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Embedding\n",
    "print(\"--- With Word2Vec Embedding ---\")\n",
    "w2v_cols = [col for col in w2v_emb.columns if col != 'zpid']\n",
    "y_pred_w2v = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': w2v_cols})\n",
    "evaluate(y_true, y_pred_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedding\n",
    "print(\"--- With BERT Embedding ---\")\n",
    "bert_cols = [col for col in bert_emb.columns if col != 'zpid']\n",
    "y_pred_bert = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': bert_cols})\n",
    "evaluate(y_true, y_pred_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Transformer Embedding\n",
    "print(\"--- With Sentence Transformer Embedding ---\")\n",
    "stf_cols = [col for col in stf_emb.columns if col != 'zpid']\n",
    "y_pred_stf = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': stf_cols})\n",
    "evaluate(y_true, y_pred_stf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Embedding\n",
    "print(\"--- With GPT Embedding ---\")\n",
    "gpt_cols = [col for col in gpt_emb.columns if col != 'zpid']\n",
    "y_pred_gpt = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': gpt_cols})\n",
    "evaluate(y_true, y_pred_gpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot (randomly pick 10 examples as context)\n",
    "print(\"--- Few-shot ---\")\n",
    "few_shot_context = sample_df.sample(n=10, random_state=7)\n",
    "remaining_df = sample_df.drop(few_shot_context.index)\n",
    "y_pred_fewshot = run_llama_classification(remaining_df, lambda r: build_few_shot_prompt(few_shot_context, r))\n",
    "evaluate(remaining_df['fast_label'].tolist(), y_pred_fewshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = []\n",
    "def append_result(label, y_true, y_pred):\n",
    "    results_summary.append({\n",
    "        \"Method\": label,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred)\n",
    "    })\n",
    "\n",
    "append_result(\"Zero-shot\", y_true, y_pred_zero)\n",
    "append_result(\"Word2Vec\", y_true, y_pred_w2v)\n",
    "append_result(\"BERT\", y_true, y_pred_bert)\n",
    "append_result(\"SentenceTransformer\", y_true, y_pred_stf)\n",
    "append_result(\"GPT\", y_true, y_pred_gpt)\n",
    "append_result(\"Few-shot\", remaining_df['fast_label'].tolist(), y_pred_fewshot)\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "\n",
    "\n",
    "print(\"\n",
    "=== Performance Summary ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
