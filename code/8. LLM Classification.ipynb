{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings or features from prior steps\n",
    "# Placeholder: Replace with actual paths or download links\n",
    "zillow_df = gpd.read_file('../dataset/raw/2. zillow_cleaned.geojson')\n",
    "w2v_emb = pd.read_csv('../dataset/raw/4. w2v_embedding.csv')\n",
    "w2v_pca = pd.read_csv('../dataset/raw/4. w2v_pca.csv')\n",
    "bert_emb = pd.read_csv('../dataset/raw/4. bert_embedding.csv')\n",
    "bert_pca = pd.read_csv('../dataset/raw/4. bert_pca.csv')\n",
    "stf_emb = pd.read_csv('../dataset/raw/5. stf_embedding.csv')\n",
    "stf_pca = pd.read_csv('../dataset/raw/5. stf_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully: (10111, 385)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Dropbox direct download link\n",
    "url_gpt_emb = 'https://www.dropbox.com/scl/fi/gcrk2mejy3su7nt9gf30i/5.-stf_embedding.csv?rlkey=d5uy0qm80geh81qxhxbtyms66&st=46sngliz&dl=1'\n",
    "\n",
    "# Load directly into DataFrame\n",
    "response = requests.get(url_gpt_emb)\n",
    "if response.status_code == 200:\n",
    "    gpt_emb = pd.read_csv(StringIO(response.text))\n",
    "    print(\"CSV loaded successfully:\", gpt_emb.shape)\n",
    "else:\n",
    "    print(\"Failed to fetch the file:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully: (10111, 33)\n"
     ]
    }
   ],
   "source": [
    "# Dropbox direct download link\n",
    "url_gpt_pca = 'https://www.dropbox.com/scl/fi/6gdiftk79r00a3uecf9zv/5.-stf_pca.csv?rlkey=j8e7e5tt81w2yt6fd3968mdwp&st=5wwf7fib&dl=1'\n",
    "\n",
    "# Load directly into DataFrame\n",
    "response = requests.get(url_gpt_pca)\n",
    "if response.status_code == 200:\n",
    "    gpt_pca = pd.read_csv(StringIO(response.text))\n",
    "    print(\"CSV loaded successfully:\", gpt_pca.shape)\n",
    "else:\n",
    "    print(\"Failed to fetch the file:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = zillow_df.copy()\n",
    "\n",
    "zillow_df['zpid'] = zillow_df['zpid'].astype(str)\n",
    "w2v_emb['zpid'] = w2v_emb['zpid'].astype(str)\n",
    "bert_emb['zpid'] = bert_emb['zpid'].astype(str)\n",
    "stf_emb['zpid'] = stf_emb['zpid'].astype(str)\n",
    "gpt_emb['zpid'] = gpt_emb['zpid'].astype(str)\n",
    "df_all = df_all.merge(w2v_emb, on=\"zpid\", how=\"left\")\n",
    "df_all = df_all.merge(bert_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_bert\"))\n",
    "df_all = df_all.merge(stf_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_stf\"))\n",
    "df_all = df_all.merge(gpt_emb, on=\"zpid\", how=\"left\", suffixes=(\"\", \"_gpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Label: Fast-Selling (TOP 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['duration'] = df_all['duration'].astype(float)\n",
    "df_all['city'] = df_all['city'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fast_label(group):\n",
    "    threshold = group['duration'].quantile(0.25)\n",
    "    return group['duration'] <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdsn\\AppData\\Local\\Temp\\ipykernel_230928\\2106994927.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_all['fast_label'] = df_all.groupby('city', group_keys=False).apply(assign_fast_label).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_all['fast_label'] = df_all.groupby('city', group_keys=False).apply(assign_fast_label).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLaMA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030bd9de55b54372aef56447f6ae0bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "llama_32_1b = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "llama_32_3b = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "generator = pipeline(model=llama_32_3b, device=device, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "wordlist_dir = \"../dataset/word_counts/0.25/\"\n",
    "wordlist_files = glob.glob(os.path.join(wordlist_dir, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'zscore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_230928\\164408736.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordlist_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbasename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_zscore.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcity_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcity_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"CH\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Chicago\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NY\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"New York\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LA\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Los Angeles\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcity_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcity_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mhouse_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Single Family\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mgroup_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"0\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"Condo/Townhouse\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"zscore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtopic_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhouse_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7185\u001b[0m             )\n\u001b[0;32m   7186\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7187\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7189\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7191\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7192\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'zscore'"
     ]
    }
   ],
   "source": [
    "# Map from (city, type) to word list\n",
    "topic_words = {}\n",
    "for path in wordlist_files:\n",
    "    basename = os.path.basename(path).replace(\"_zscore.csv\", \"\")\n",
    "    city_code, group_id, *_ = basename.split(\"_\")\n",
    "    city_map = {\"CH\": \"Chicago\", \"NY\": \"New York\", \"LA\": \"Los Angeles\"}\n",
    "    city = city_map[city_code]\n",
    "    house_type = \"Single Family\" if group_id == \"0\" else \"Condo/Townhouse\"\n",
    "    df_words = pd.read_csv(path).sort_values(\"zscore\", ascending=False).head(50)\n",
    "    topic_words[(city, house_type)] = df_words['word'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zero_shot_prompt(row):\n",
    "    return f\"\"\"\n",
    "    <Task> Classify whether the house is fast-selling or not.\n",
    "    <House Info>\n",
    "    - Address: {row['address']}, {row['city']}\n",
    "    - Type: {'Single Family' if row['single'] == 0 else 'Condo/Townhouse'}\n",
    "    - Description: {row['description']}\n",
    "    - Days on Market: {row['duration']}\n",
    "    <Question> Is this a fast-selling house? Answer only 'Yes' or 'No'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_prompt(row, embedding_columns):\n",
    "    embed_values = \", \".join([f\"{col}: {row[col]:.4f}\" for col in embedding_columns if not pd.isna(row[col])])\n",
    "    return f\"\"\"\n",
    "    <Task> Given the house description and its embedding values, classify whether the house is fast-selling.\n",
    "    <Description>: {row['description']}\n",
    "    <Embeddings>: {embed_values}\n",
    "    <Question>: Is this a fast-selling house? Answer 'Yes' or 'No'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_few_shot_prompt(df_context, row):\n",
    "    examples = \"\\n\".join([\n",
    "        f\"Example {i+1} -> Description: {r['description']}\\nFast Selling: {'Yes' if r['fast_label'] else 'No'}\"\n",
    "        for i, (_, r) in enumerate(df_context.iterrows())\n",
    "    ])\n",
    "    return f\"\"\"\n",
    "    <Task> Determine whether the house is fast-selling based on its description.\n",
    "    {examples}\n",
    "    Now classify this house:\n",
    "    Description: {row['description']}\n",
    "    <Question> Fast Selling? Answer 'Yes' or 'No'.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topic_prompt(row):\n",
    "    region = row['city']\n",
    "    house_type = \"Single Family\" if row['single'] == 0 else \"Condo/Townhouse\"\n",
    "    keywords = topic_words.get((region, house_type), [])\n",
    "    wordlist = \", \".join(keywords)\n",
    "    return f\"\"\"\n",
    "    <Task> You are given a house listing. Below is a list of words that are frequently used in fast-selling houses in this region and house type.\n",
    "    <Region>: {region}, <Type>: {house_type}\n",
    "    <Keywords>: {wordlist}\n",
    "    <Description>: {row['description']}\n",
    "    <Question>: Based on the keywords and the description, is this house fast-selling? Answer strictly with 'Yes' or 'No'.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_llama_classification(df_subset, prompt_func, prompt_args=None):\n",
    "#     predictions = []\n",
    "#     for _, row in df_subset.iterrows():\n",
    "#         if prompt_args:\n",
    "#             prompt = prompt_func(row, **prompt_args)\n",
    "#         else:\n",
    "#             prompt = prompt_func(row)\n",
    "#         result = generator(\n",
    "#             prompt,\n",
    "#             max_new_tokens=10,\n",
    "#             do_sample=True,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.9,\n",
    "#             pad_token_id=generator.tokenizer.eos_token_id\n",
    "#         )[0]['generated_text']\n",
    "#         predictions.append(\"Yes\" in result)\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llama_classification(df_subset, prompt_func, prompt_args=None):\n",
    "    prompts = []\n",
    "    for _, row in df_subset.iterrows():\n",
    "        prompt = prompt_func(row, **prompt_args) if prompt_args else prompt_func(row)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    generations = generator(\n",
    "        prompts,\n",
    "        max_new_tokens=10,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    for gen in generations:\n",
    "        response = gen[\"generated_text\"][-1][\"content\"] if isinstance(gen[\"generated_text\"], list) else gen[\"generated_text\"]\n",
    "        answer = response.strip().split()[-1].lower()\n",
    "        predictions.append(\"yes\" in answer)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data sample\n",
    "sample_df = df_all.dropna(subset=['description', 'duration']).sample(n=50, random_state=42)\n",
    "y_true = sample_df['fast_label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Zero-shot ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22\n",
      "Precision: 0.22\n",
      "Recall: 1.0\n",
      "F1 Score: 0.36065573770491804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        39\n",
      "           1       0.22      1.00      0.36        11\n",
      "\n",
      "    accuracy                           0.22        50\n",
      "   macro avg       0.11      0.50      0.18        50\n",
      "weighted avg       0.05      0.22      0.08        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cdsn\\anaconda3\\envs\\yj_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Zero-shot ---\")\n",
    "y_pred_zero = run_llama_classification(sample_df, build_zero_shot_prompt)\n",
    "evaluate(y_true, y_pred_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- With Word2Vec Embedding ---\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec Embedding\n",
    "print(\"--- With Word2Vec Embedding ---\")\n",
    "w2v_cols = [col for col in w2v_emb.columns if col != 'zpid']\n",
    "y_pred_w2v = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': w2v_cols})\n",
    "evaluate(y_true, y_pred_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedding\n",
    "print(\"--- With BERT Embedding ---\")\n",
    "bert_cols = [col for col in bert_emb.columns if col != 'zpid']\n",
    "y_pred_bert = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': bert_cols})\n",
    "evaluate(y_true, y_pred_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Transformer Embedding\n",
    "print(\"--- With Sentence Transformer Embedding ---\")\n",
    "stf_cols = [col for col in stf_emb.columns if col != 'zpid']\n",
    "y_pred_stf = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': stf_cols})\n",
    "evaluate(y_true, y_pred_stf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Embedding\n",
    "print(\"--- With GPT Embedding ---\")\n",
    "gpt_cols = [col for col in gpt_emb.columns if col != 'zpid']\n",
    "y_pred_gpt = run_llama_classification(sample_df, build_embedding_prompt, {'embedding_columns': gpt_cols})\n",
    "evaluate(y_true, y_pred_gpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot (randomly pick 10 examples as context)\n",
    "print(\"--- Few-shot ---\")\n",
    "few_shot_context = sample_df.sample(n=10, random_state=7)\n",
    "remaining_df = sample_df.drop(few_shot_context.index)\n",
    "y_pred_fewshot = run_llama_classification(remaining_df, lambda r: build_few_shot_prompt(few_shot_context, r))\n",
    "evaluate(remaining_df['fast_label'].tolist(), y_pred_fewshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Keyword-Aware Prompt ---\")\n",
    "y_pred_keywords = run_llama_classification(sample_df, build_topic_prompt)\n",
    "evaluate(y_true, y_pred_keywords)\n",
    "append_result(\"Keyword-Aware\", y_true, y_pred_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = []\n",
    "def append_result(label, y_true, y_pred):\n",
    "    results_summary.append({\n",
    "        \"Method\": label,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred)\n",
    "    })\n",
    "\n",
    "append_result(\"Zero-shot\", y_true, y_pred_zero)\n",
    "append_result(\"Word2Vec\", y_true, y_pred_w2v)\n",
    "append_result(\"BERT\", y_true, y_pred_bert)\n",
    "append_result(\"SentenceTransformer\", y_true, y_pred_stf)\n",
    "append_result(\"GPT\", y_true, y_pred_gpt)\n",
    "append_result(\"Few-shot\", remaining_df['fast_label'].tolist(), y_pred_fewshot)\n",
    "append_result(\"Keyword-Aware Few-shot\", remaining_df['Keyword-Aware'].tolist(), y_pred_keywords)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "\n",
    "\n",
    "print(\"\n",
    "=== Performance Summary ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
